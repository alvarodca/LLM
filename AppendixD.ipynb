{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alvarodca/LLM/blob/main/AppendixD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQc-6No0GnSX"
      },
      "source": [
        "# **APPENDIX D**\n",
        "\n",
        "In this appendix, we enhance the training function for the pretraining and finetuning processes covered in chapters 5 to 7\n",
        "\n",
        "In particular, it covers learning rate warmup, cosine decay, and gradient clipping\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0p3JUA3VGmTD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gQVwP9ePGzn5"
      },
      "outputs": [],
      "source": [
        "# Multi Head attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        " def __init__(self, d_in, d_out,\n",
        "    context_length, dropout, num_heads, qkv_bias=False):\n",
        "    super().__init__()\n",
        "\n",
        "    assert (d_out % num_heads == 0), \\\n",
        "    \"d_out must be divisible by num_heads\" # We need dimensions to align as we may lose dimensions in the process if not.\n",
        "\n",
        "    self.d_out = d_out\n",
        "    self.num_heads = num_heads\n",
        "    self.head_dim = d_out // num_heads # Makes sure each attention head has equal dimensions\n",
        "\n",
        "    self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "    self.out_proj = nn.Linear(d_out, d_out) # Layer to combine outpute\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.register_buffer(\n",
        "    \"mask\",\n",
        "    torch.triu(torch.ones(context_length, context_length),\n",
        "    diagonal=1)\n",
        "    )\n",
        "\n",
        "\n",
        " def forward(self, x):\n",
        "    b, num_tokens, d_in = x.shape # b <- batch size, num_tokens <- sequence length, d_in <- input embedding\n",
        "\n",
        "    # shape = [b,num_tokens, d_out] where d_out = num_heads * head_dim\n",
        "    keys = self.W_key(x)\n",
        "    queries = self.W_query(x)\n",
        "    values = self.W_value(x)\n",
        "\n",
        "    # Split the values into Heads, shape = [b, num_tokens, num_heads, head_dim]\n",
        "    keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "    queries = queries.view(\n",
        "    b, num_tokens, self.num_heads, self.head_dim\n",
        "    )\n",
        "\n",
        "    # As we are using nn.Linear we need to transpose our matrices\n",
        "    keys = keys.transpose(1, 2)\n",
        "    queries = queries.transpose(1, 2)\n",
        "    values = values.transpose(1, 2)\n",
        "\n",
        "    # Computes dot product for each head\n",
        "    attn_scores = queries @ keys.transpose(2, 3)\n",
        "\n",
        "    # Masking\n",
        "    mask_bool = self.mask.bool()[:num_tokens, :num_tokens]  # Mask fixed to token number\n",
        "    attn_scores.masked_fill_(mask_bool, -torch.inf) # Uses mask to fill attention scores\n",
        "\n",
        "    # Softmax + Dropout\n",
        "    attn_weights = torch.softmax(\n",
        "    attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    # Context vector\n",
        "    context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "    # Combine all heads\n",
        "    context_vec = context_vec.contiguous().view(\n",
        "    b, num_tokens, self.d_out\n",
        "    )\n",
        "    # Mix information to a single simple layer\n",
        "    context_vec = self.out_proj(context_vec)\n",
        "    return context_vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Text generator\n",
        "def generate_text_simple(model, idx,\n",
        "    max_new_tokens, context_size):\n",
        "    # Uses only the maximum amount of selected tokens\n",
        "    for _ in range(max_new_tokens):\n",
        "        idx_cond = idx[:, -context_size:] # Takes the selected tokens as input\n",
        "        with torch.no_grad(): # No gradient calculating (prediction)\n",
        "            logits = model(idx_cond) # Output prediction\n",
        "\n",
        "        logits = logits[:, -1, :] # Logits for the last token (predicting the last wrod)\n",
        "        probas = torch.softmax(logits, dim=-1) # Values to probabilities (softmax) not strictly necessary\n",
        "        idx_next = torch.argmax(probas, dim=-1, keepdim=True) # Selects the highest value\n",
        "        idx = torch.cat((idx, idx_next), dim=1) # Appends to the previous tokens\n",
        "    return idx\n",
        "\n",
        "# GELU\n",
        "class GELU(nn.Module):\n",
        " def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        " def forward(self, x):\n",
        "    return 0.5 * x * (1 + torch.tanh(\n",
        "    torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "    (x + 0.044715 * torch.pow(x, 3))\n",
        "    ))\n",
        "\n",
        "# FEED FORWARD\n",
        "class FeedForward(nn.Module):\n",
        " def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    # Neural layers\n",
        "    self.layers = nn.Sequential(\n",
        "    nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), # Increases embedding by 4\n",
        "    GELU(),\n",
        "    nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), # Decreases embedding by 4\n",
        "    )\n",
        " def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "# TRANSFORMER BLOCK\n",
        "class TransformerBlock(nn.Module):\n",
        " def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    \"\"\"Init method\n",
        "        d_in = input embedding size\n",
        "        d_out = output embedding size\n",
        "        context_length = max number of tokens in a sentence\n",
        "        num_heads = number of heads to use\n",
        "        dropout = droput rate\n",
        "        qkv_bias = whether to add bias\"\"\"\n",
        "    self.att = MultiHeadAttention(\n",
        "    d_in=cfg[\"emb_dim\"],\n",
        "    d_out=cfg[\"emb_dim\"],\n",
        "    context_length=cfg[\"context_length\"],\n",
        "    num_heads=cfg[\"n_heads\"],\n",
        "    dropout=cfg[\"drop_rate\"],\n",
        "    qkv_bias=cfg[\"qkv_bias\"])\n",
        "\n",
        "    # FeedForward structure\n",
        "    self.ff = FeedForward(cfg)\n",
        "\n",
        "    # Normalizes inputs before the different blocks <- PreLayerNorm\n",
        "    self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "    self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "\n",
        "    # Dropout layer\n",
        "    self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        " def forward(self, x): # Enables shortcut connections\n",
        "\n",
        "    # FIrst block of our previously shown picture\n",
        "    shortcut = x\n",
        "    x = self.norm1(x) # Normalize input\n",
        "    x = self.att(x) # Self-attention\n",
        "    x = self.drop_shortcut(x) # Dropout\n",
        "    x = x + shortcut # Residual connection\n",
        "\n",
        "    # Second block\n",
        "    shortcut = x\n",
        "    x = self.norm2(x) # Normalize\n",
        "    x = self.ff(x) # FeedForward\n",
        "    x = self.drop_shortcut(x) # Dropout\n",
        "    x = x + shortcut # Residual\n",
        "    return x\n",
        "\n",
        "\n",
        "# LAYERNORM\n",
        "class LayerNorm(nn.Module):\n",
        " def __init__(self, emb_dim): # emb_dim is the last dimension, to work with these numbers\n",
        "    super().__init__()\n",
        "    self.eps = 1e-5 # Small value to avoid division by 0\n",
        "    # Trainable parameters\n",
        "    self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "    self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        " def forward(self, x):\n",
        "    # Applies normalization\n",
        "    mean = x.mean(dim=-1, keepdim=True)\n",
        "    var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "    norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "    return self.scale * norm_x + self.shift\n"
      ],
      "metadata": {
        "id": "-2L8oNA9HFbW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT MODEL\n",
        "class GPTModel(nn.Module):\n",
        " def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    # Token and positional embedding layers, convert tokens into vectors and add valuable information\n",
        "    self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "    self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "    self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    # Sequential Stack of Transformer Block equal to the number of layers\n",
        "    self.trf_blocks = nn.Sequential(\n",
        "    *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "    # Layer Norm to standardize outputs\n",
        "    self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "\n",
        "    # Output into the vocabulary\n",
        "    self.out_head = nn.Linear(\n",
        "    cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
        "    )\n",
        "\n",
        " def forward(self, in_idx):\n",
        "    batch_size, seq_len = in_idx.shape\n",
        "    # Computes embeddings\n",
        "    tok_embeds = self.tok_emb(in_idx)\n",
        "    pos_embeds = self.pos_emb(\n",
        "    torch.arange(seq_len, device=in_idx.device)\n",
        "    )\n",
        "    # Adds embeddings\n",
        "    x = tok_embeds + pos_embeds\n",
        "    x = self.drop_emb(x) # Dropout\n",
        "    x = self.trf_blocks(x) # Transformer Blocks\n",
        "    x = self.final_norm(x) # Normalization\n",
        "    logits = self.out_head(x) # Output\n",
        "    return logits\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RPiDsbdkHIwB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reinitializing the model\n",
        "import torch\n",
        "\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        " \"vocab_size\": 50257,\n",
        " \"context_length\": 256,\n",
        " \"emb_dim\": 768,\n",
        " \"n_heads\": 12,\n",
        " \"n_layers\": 12,\n",
        " \"drop_rate\": 0.1,\n",
        " \"qkv_bias\": False\n",
        "}\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9XdoNf_HNi-",
        "outputId": "3ad453b8-2abb-4978-8b3d-ee4628d64b98"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPTModel(\n",
              "  (tok_emb): Embedding(50257, 768)\n",
              "  (pos_emb): Embedding(256, 768)\n",
              "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
              "  (trf_blocks): Sequential(\n",
              "    (0): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (1): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (2): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (3): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (4): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (5): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (6): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (7): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (8): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (9): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (10): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (11): TransformerBlock(\n",
              "      (att): MultiHeadAttention(\n",
              "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
              "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (ff): FeedForward(\n",
              "        (layers): Sequential(\n",
              "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (1): GELU()\n",
              "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "        )\n",
              "      )\n",
              "      (norm1): LayerNorm()\n",
              "      (norm2): LayerNorm()\n",
              "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (final_norm): LayerNorm()\n",
              "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtaining input data\n"
      ],
      "metadata": {
        "id": "F7m7gDG1JP1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "file_path = \"the-verdict.txt\"\n",
        "url = (\n",
        " \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/\"\n",
        " \"main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
        ")\n",
        "if not os.path.exists(file_path):\n",
        " with urllib.request.urlopen(url) as response:\n",
        "  text_data = response.read().decode('utf-8')\n",
        " with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "  file.write(text_data)\n",
        "else:\n",
        " with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "  text_data = file.read()"
      ],
      "metadata": {
        "id": "YqTp4U6YJS1O"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data onto DataLoaders"
      ],
      "metadata": {
        "id": "oZn60BPpHk6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n",
        "class GPTDatasetV1(Dataset):\n",
        "    def __init__(self, txt, tokenizer, max_length, stride):\n",
        "        \"\"\"Init method\n",
        "        txt: string input text\n",
        "        tokenizer: turns text into tokens\n",
        "        max_length: int length of each input sentence\n",
        "        stride: step size between chunks, how far to move sliding window\"\"\"\n",
        "\n",
        "        self.input_ids = []\n",
        "        self.target_ids = []\n",
        "        token_ids = tokenizer.encode(txt) # Tokenizes the entire text\n",
        "\n",
        "        for i in range(0, len(token_ids) - max_length, stride): # Uses a sliding window\n",
        "            input_chunk = token_ids[i:i + max_length] # Set of words of max length\n",
        "            target_chunk = token_ids[i + 1: i + max_length + 1] # The next max length\n",
        "            self.input_ids.append(torch.tensor(input_chunk)) # Stored as tensors\n",
        "            self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_ids) # Returns the total number of rows from the dataset\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.input_ids[idx], self.target_ids[idx] # Returns a single row from the dataset\n",
        "\n",
        "\n",
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "    stride=128, shuffle=True, drop_last=True,\n",
        "    num_workers=0):\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\") # Tokenized\n",
        "\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride) # Creates dataset\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=shuffle,\n",
        "    drop_last=drop_last, # True to avoid errors in training\n",
        "    num_workers=num_workers\n",
        "    )\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "UR99M6Y1HnPi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data\n",
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(text_data))\n",
        "torch.manual_seed(123)\n",
        "train_loader = create_dataloader_v1(\n",
        " text_data[:split_idx],\n",
        " batch_size=2,\n",
        " max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        " stride=GPT_CONFIG_124M[\"context_length\"],\n",
        " drop_last=True,\n",
        " shuffle=True,\n",
        " num_workers=0\n",
        ")\n",
        "val_loader = create_dataloader_v1(\n",
        " text_data[split_idx:],\n",
        " batch_size=2,\n",
        " max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        " stride=GPT_CONFIG_124M[\"context_length\"],\n",
        " drop_last=False,\n",
        " shuffle=False,\n",
        " num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "-080zd-kJB44"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Learning Rate Warmup**\n",
        "\n",
        "This process involves gradually increasing the learning rate from a very\n",
        "low initial value (initial_lr) to a maximum value specified by the user (peak_lr).\n",
        "Starting the training with smaller weight updates decreases the risk of the model\n",
        "encountering large, destabilizing updates during its training phase.\n",
        "\n",
        "\n",
        "Warmup steps refer to the number of training steps (or sometimes epochs) during which the learning rate is gradually increased from 0 (or a small value) to the target learning rate."
      ],
      "metadata": {
        "id": "FKi0HIoqIRn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 15\n",
        "initial_lr = 0.0001\n",
        "peak_lr = 0.01\n",
        "warmup_steps = 20\n",
        "\n",
        "total_steps = len(train_loader) * n_epochs\n",
        "warmup_steps = int(0.2 * total_steps)\n",
        "print(\"Warmup steps:\",warmup_steps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl_a6We7Ih1W",
        "outputId": "5f50ec9b-8d6f-4abf-db84-b6812f8b6e68"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warmup steps: 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This prints 27, meaning that we have 20 warmup steps to increase the initial learning\n",
        "rate from 0.0001 to 0.01 in the first 27 training steps."
      ],
      "metadata": {
        "id": "cumNm72jJgZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creates AdamW optimizer with weight decay\n",
        "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.1)\n",
        "# How much learning rate should increase per step during warmup\n",
        "lr_increment = (peak_lr - initial_lr) / warmup_steps\n",
        "# Optimizer steps taken\n",
        "global_step = -1\n",
        "# Stores learning rate at each step\n",
        "track_lrs = []\n",
        "\n",
        "# Loop through epochs and batches\n",
        "for epoch in range(n_epochs):\n",
        " for input_batch, target_batch in train_loader:\n",
        "  optimizer.zero_grad() # Gradients back to 0\n",
        "  global_step += 1 # One more step\n",
        "\n",
        "  # During warmup\n",
        "  if global_step < warmup_steps:\n",
        "    lr = initial_lr + global_step * lr_increment # Change in learning rate\n",
        "  # After warmup\n",
        "  else:\n",
        "    lr = peak_lr\n",
        "\n",
        "  # Sets the same lr for all parameters\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group[\"lr\"] = lr\n",
        "\n",
        "  # Stores learning rate\n",
        "  track_lrs.append(optimizer.param_groups[0][\"lr\"])"
      ],
      "metadata": {
        "id": "pD-87kPuJkid"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick test of the code\n",
        "import matplotlib.pyplot as plt\n",
        "plt.ylabel(\"Learning rate\")\n",
        "plt.xlabel(\"Step\")\n",
        "total_training_steps = len(train_loader) * n_epochs\n",
        "plt.plot(range(total_training_steps), track_lrs);\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "5i3G-dNvK9eX",
        "outputId": "3d77165f-2757-41fc-948a-2a6f257a6cb2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAGwCAYAAACNeeBZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAARFBJREFUeJzt3Xl8lOW9///3THYgG4kkBAIJEIsKsiQQAqEcazRaWo1aCxyOIHKgtqgoKAVkqR49VCpqqVT0/HrEnpYD5bRF5atUGlS2ECQsisi+BMEESMhCINvM/fsjzuBIwAxZ7llez8djHph7rrnnc19G5u19XXNdFsMwDAEAAOCaWM0uAAAAwJsRpgAAAJqBMAUAANAMhCkAAIBmIEwBAAA0A2EKAACgGQhTAAAAzRBodgHeym6369SpUwoPD5fFYjG7HAAA0ASGYaiyslIJCQmyWlvmnhJh6hqdOnVKiYmJZpcBAACuwYkTJ9S1a9cWORdh6hqFh4dLaviXERERYXI1AACgKSoqKpSYmOj8HG8JhKlr5Bjai4iIIEwBAOBlWnKKDhPQAQAAmoEwBQAA0AyEKQAAgGYgTAEAADQDYQoAAKAZCFMAAADNQJgCAABoBsIUAABAMxCmAAAAmoEwBQAA0Aymh6klS5YoKSlJoaGhSk9P17Zt267aftWqVerdu7dCQ0PVt29fvffeey7P/+1vf9Ptt9+umJgYWSwW7dq167JzVFdXa8qUKYqJiVGHDh103333qbi4uCUvCwAA+AlTw9TKlSs1bdo0zZ8/Xzt27FC/fv2UnZ2t06dPN9p+y5YtGjNmjCZOnKidO3cqJydHOTk52rNnj7NNVVWVMjMz9cILL1zxfZ944gm9++67WrVqlT7++GOdOnVK9957b4tfHwAA8H0WwzAMs948PT1dgwYN0quvvipJstvtSkxM1KOPPqqZM2de1n7UqFGqqqrSmjVrnMeGDBmi/v37a+nSpS5tjx07puTkZO3cuVP9+/d3Hi8vL9d1112n5cuX6yc/+Ykkad++fbrhhhuUl5enIUOGNKn2iooKRUZGqry8nI2OvZTdbuirimqZ+J8AAOAqYjuEKDQooEXP2Rqf34EtcpZrUFtbq4KCAs2aNct5zGq1KisrS3l5eY2+Ji8vT9OmTXM5lp2drdWrVzf5fQsKClRXV6esrCznsd69e6tbt25XDVM1NTWqqalx/lxRUdHk94Rnmvw/2/XPLxq/CwoAMN8fHxqs719/ndllfCfTwtTZs2dls9kUFxfncjwuLk779u1r9DVFRUWNti8qKmry+xYVFSk4OFhRUVFunWfBggV65plnmvw+8GznqmqVu68hSIUEmj51EADQCKvFYnYJTWJamPI2s2bNcrkrVlFRocTERBMrQnNsOVwiw5BSOnXQumkjzC4HAODFTAtTsbGxCggIuOxbdMXFxYqPj2/0NfHx8W61v9I5amtrVVZW5nJ36rvOExISopCQkCa/DzzbpkNnJEmZKbEmVwIA8HamjW8EBwcrNTVVubm5zmN2u125ubnKyMho9DUZGRku7SVp3bp1V2zfmNTUVAUFBbmcZ//+/SosLHTrPPBehmFow4GzkqTvp3j+WDwAwLOZOsw3bdo0jR8/XmlpaRo8eLBeeeUVVVVVacKECZKkcePGqUuXLlqwYIEkaerUqRoxYoQWLVqkkSNHasWKFdq+fbveeOMN5zlLS0tVWFioU6dOSWoISlLDHan4+HhFRkZq4sSJmjZtmjp27KiIiAg9+uijysjIaPI3+eDdjpVc0MmyiwoKsCi9R0ezywEAeDlTw9SoUaN05swZzZs3T0VFRerfv7/Wrl3rnGReWFgoq/XSzbOhQ4dq+fLlmjNnjmbPnq2UlBStXr1affr0cbZ55513nGFMkkaPHi1Jmj9/vn71q19Jkl5++WVZrVbdd999qqmpUXZ2tn7/+9+3wRXDE2w62DDEN7BbtNoFM20QANA8pq4z5c1YZ8p7Tf7jdn2wt1hP3n69HvlBitnlAADaUGt8fvOdcPiVeptdeYdLJEmZzJcCALQAwhT8yu4vy1RZU6/IsCD17RJpdjkAAB9AmIJf2Xiw4Vt8w3rFKMDqHYvBAQA8G2EKfmXT12EqsxdDfACAlkGYgt+orK7TzhNlkqThLNYJAGghhCn4ja1HSmWzG0qKaafEju3MLgcA4CMIU/AbGw+yhQwAoOURpuA3mC8FAGgNhCn4hZNlF3XkbJWsFimjZ4zZ5QAAfAhhCn7BsYVMv8QoRYYFmVwNAMCXEKbgFzZ8PcQ3nFXPAQAtjDAFn2e3G9pyyBGmmHwOAGhZhCn4vM9PVejchTp1CAlU/8Qos8sBAPgYwhR83sZDDfOlhvToqKAAfuUBAC2LTxb4vE3MlwIAtCLCFHzaxVqbth87J4nFOgEArYMwBZ+Wf7REtTa7EiJD1SO2vdnlAAB8EGEKPs256nlKrCwWi8nVAAB8EWEKPm3TIUeYYr4UAKB1EKbgs05XVGtfUaUsFimzF/OlAACtgzAFn+W4K3VTQoQ6tg82uRoAgK8iTMFnOedL9WKIDwDQeghT8EmGYTjvTLGFDACgNRGm4JMOFJ/X6coahQZZldo92uxyAAA+jDAFn7TxYMMWMoOTYxQaFGByNQAAX0aYgk/a6NhChm/xAQBaGWEKPqem3qb8oyWS2EIGAND6CFPwOQXHz6m6zq7YDiHqHR9udjkAAB9HmILPcQ7xsYUMAKANEKbgcy6tL8UQHwCg9RGm4FPOVdVqz6lyScyXAgC0DcIUfMrmw2dlGNL1cR0UFxFqdjkAAD9AmIJP2eScL8UWMgCAtkGYgs8wDMM5+ZwhPgBAWyFMwWccPVulk2UXFRxgVXpyR7PLAQD4CcIUfIZjY+OB3aPULjjQ5GoAAP6CMAWfsZH5UgAAExCm4BPqbHblHW7YQmY486UAAG2IMAWfsPtEmc7X1CuqXZBuSog0uxwAgB8hTMEnOIb4hvWMVYCVLWQAAG2HMAWf4Jh8zpIIAIC2RpiC16uortOuE2WS2I8PAND2CFPwenmHS2SzG0qOba/Eju3MLgcA4GcIU/B6ji1kuCsFADADYQpej/lSAAAzEabg1U6UXtDRs1UKsFqU0TPG7HIAAH6IMAWv5rgr1T8xShGhQSZXAwDwR4QpeDXmSwEAzEaYgtey2Q1tPuzYj48wBQAwB2EKXuvzU+Uqu1CnDiGB6pcYZXY5AAA/RZiC13JsIZPRM0ZBAfwqAwDMwScQvNbGg2ckMcQHADAXYQpe6UJtvQqOn5PE5HMAgLkIU/BK+UdLVWcz1CUqTMmx7c0uBwDgxwhT8EqOJRGGp8TKYrGYXA0AwJ8RpuCVHPOl2EIGAGA2whS8TnFFtQ4Un5fFIg3rSZgCAJjL9DC1ZMkSJSUlKTQ0VOnp6dq2bdtV269atUq9e/dWaGio+vbtq/fee8/lecMwNG/ePHXu3FlhYWHKysrSwYMHXdocOHBAd999t2JjYxUREaHMzEx9+OGHLX5taB2OIb4+CZGKbh9scjUAAH9naphauXKlpk2bpvnz52vHjh3q16+fsrOzdfr06Ubbb9myRWPGjNHEiRO1c+dO5eTkKCcnR3v27HG2WbhwoRYvXqylS5cqPz9f7du3V3Z2tqqrq51tfvSjH6m+vl7r169XQUGB+vXrpx/96EcqKipq9WtG8zn242OIDwDgCSyGYRhmvXl6eroGDRqkV199VZJkt9uVmJioRx99VDNnzrys/ahRo1RVVaU1a9Y4jw0ZMkT9+/fX0qVLZRiGEhISNH36dD355JOSpPLycsXFxWnZsmUaPXq0zp49q+uuu04bNmzQ8OHDJUmVlZWKiIjQunXrlJWV1aTaKyoqFBkZqfLyckVERDS3K9BEhmFo0PO5Onu+RssnpWsow3wAADe0xue3aXemamtrVVBQ4BJerFarsrKylJeX1+hr8vLyLgs72dnZzvZHjx5VUVGRS5vIyEilp6c728TExOh73/ue/vjHP6qqqkr19fV6/fXX1alTJ6Wmpl6x3pqaGlVUVLg80Pb2FVXq7PkahQUFKLV7tNnlAABgXpg6e/asbDab4uLiXI7HxcVdcbitqKjoqu0df16tjcVi0T//+U/t3LlT4eHhCg0N1UsvvaS1a9cqOvrKH84LFixQZGSk85GYmOjeBaNFOOZLDU7uqJDAAJOrAQDAAyagtzXDMDRlyhR16tRJGzdu1LZt25STk6Mf//jH+uqrr674ulmzZqm8vNz5OHHiRBtWDYeNhy6tLwUAgCcwLUzFxsYqICBAxcXFLseLi4sVHx/f6Gvi4+Ov2t7x59XarF+/XmvWrNGKFSs0bNgwDRw4UL///e8VFhamt95664r1hoSEKCIiwuWBtlVdZ9O2oyWSpOEp15lcDQAADUwLU8HBwUpNTVVubq7zmN1uV25urjIyMhp9TUZGhkt7SVq3bp2zfXJysuLj413aVFRUKD8/39nmwoULkhrmZ32T1WqV3W5v/oWh1RQcP6fqOrs6hYfo+rgOZpcDAIAkKdDMN582bZrGjx+vtLQ0DR48WK+88oqqqqo0YcIESdK4cePUpUsXLViwQJI0depUjRgxQosWLdLIkSO1YsUKbd++XW+88YakhvlQjz/+uJ577jmlpKQoOTlZc+fOVUJCgnJyciQ1BLLo6GiNHz9e8+bNU1hYmP7rv/5LR48e1ciRI03pBzTNxq/nS2X2YgsZAIDnMDVMjRo1SmfOnNG8efNUVFSk/v37a+3atc4J5IWFhS53kIYOHarly5drzpw5mj17tlJSUrR69Wr16dPH2WbGjBmqqqrS5MmTVVZWpszMTK1du1ahoaGSGoYX165dq6efflo/+MEPVFdXp5tuuklvv/22+vXr17YdALdsOsQWMgAAz2PqOlPejHWm2lZpVa1Sn1snw5C2zb5VnSJCzS4JAOCFfGqdKcAdmw+dlWFIvePDCVIAAI9CmIJX2Hjw6yG+XgzxAQA8C2EKHs8wDOdincyXAgB4GsIUPN6Rs1U6VV6t4ACr0pNjzC4HAAAXhCl4PMddqbSkaIUFs4UMAMCzEKbg8ZzzpRjiAwB4IMIUPFqdza6tR0olScN7sYUMAMDzEKbg0XadKNP5mnpFtwvSTQms5wUA8DyEKXg0xxYyQ3vFymplCxkAgOchTMGjbfp6vtT3mS8FAPBQhCl4rPKLddp1okySlJnCfCkAgGciTMFj5R0ukd2QesS2V5eoMLPLAQCgUYQpeKxNh1gSAQDg+QhT8FiOxTqHM8QHAPBghCl4pBOlF3Ss5IICrBYN6dHR7HIAALgiwhQ8kmNJhAGJUQoPDTK5GgAArowwBY/EfCkAgLcgTMHj2OyGNh8qkSQNJ0wBADwcYQoeZ8/JcpVfrFN4SKD6dY0yuxwAAK6KMAWPs/HrVc8zesYoMIBfUQCAZ+OTCh5no3NJBIb4AACejzAFj1JVU68dhecksYUMAMA7EKbgUbYdLVWdzVDX6DAlxbQzuxwAAL4TYQoe5ZtDfBaLxeRqAAD4boQpeBTH5PPMXgzxAQC8A2EKHqOovFoHT5+XxSIN7RljdjkAADQJYQoeY9OhhiG+vl0iFd0+2ORqAABoGsIUPMamr4f4WBIBAOBNCFPwCHa74bwzxXwpAIA3IUzBI+wrqtTZ87UKCwrQwO5RZpcDAECTEabgETYdahjiS+/RUSGBASZXAwBA0xGm4BEurS/FEB8AwLsQpmC66jqbth0tlcTkcwCA9yFMwXTbj51TTb1dcREhSunUwexyAABwC2EKptv49XypYb3YQgYA4H0IUzDdpm/sxwcAgLchTMFUJedr9PmpCkkNd6YAAPA2hCmYyrFQZ+/4cHUKDzW5GgAA3EeYgqkY4gMAeDvCFExjGN/YQob1pQAAXoowBdMcPlOlr8qrFRxo1eCkjmaXAwDANSFMwTSbDjYsiTAoKVphwWwhAwDwToQpmMaxhUxmL4b4AADeizAFU9TZ7Np6pEQSk88BAN6NMAVT7CwsU1WtTR3bB+vGzhFmlwMAwDUjTMEUjvlSw3rFymplCxkAgPciTMEUGxzrS7HqOQDAyxGm0ObKL9Tp0y/LJEmZzJcCAHi5awpT9fX1+uc//6nXX39dlZWVkqRTp07p/PnzLVocfFPekbOyG1KP69orISrM7HIAAGiWQHdfcPz4cd1xxx0qLCxUTU2NbrvtNoWHh+uFF15QTU2Nli5d2hp1woc4lkT4PqueAwB8gNt3pqZOnaq0tDSdO3dOYWGX7ircc889ys3NbdHi4JucW8gwXwoA4APcvjO1ceNGbdmyRcHBwS7Hk5KSdPLkyRYrDL6psOSCjpdcUKDVoiE9Y8wuBwCAZnP7zpTdbpfNZrvs+Jdffqnw8PAWKQq+a+OhhiURBnSLUocQt7M8AAAex+0wdfvtt+uVV15x/myxWHT+/HnNnz9fP/zhD1uyNvigTWwhAwDwMW7fGli0aJGys7N14403qrq6Wv/6r/+qgwcPKjY2Vv/7v//bGjXCR9jshjZ/PV9q+PXMlwIA+Aa3w1TXrl21e/durVy5Urt379b58+c1ceJEjR071mVCOvBtn35ZporqeoWHBurmLpFmlwMAQItwO0xt2LBBQ4cO1dixYzV27Fjn8fr6em3YsEHf//73W7RA+A7HEN/QnjEKDGC9WACAb3D7E+2WW25RaWnpZcfLy8t1yy23uF3AkiVLlJSUpNDQUKWnp2vbtm1Xbb9q1Sr17t1boaGh6tu3r9577z2X5w3D0Lx589S5c2eFhYUpKytLBw8evOw8/+///T+lp6crLCxM0dHRysnJcbt2uGejY0kE1pcCAPgQt8OUYRiyWC7fmLakpETt27d361wrV67UtGnTNH/+fO3YsUP9+vVTdna2Tp8+3Wj7LVu2aMyYMZo4caJ27typnJwc5eTkaM+ePc42Cxcu1OLFi7V06VLl5+erffv2ys7OVnV1tbPNX//6Vz3wwAOaMGGCdu/erc2bN+tf//Vf3aod7qmqqdfOwnOSpO+zhQwAwIdYDMMwmtLw3nvvlSS9/fbbuuOOOxQSEuJ8zmaz6dNPP9X3vvc9rV27tslvnp6erkGDBunVV1+V1LDsQmJioh599FHNnDnzsvajRo1SVVWV1qxZ4zw2ZMgQ9e/fX0uXLpVhGEpISND06dP15JNPSmq4YxYXF6dly5Zp9OjRqq+vV1JSkp555hlNnDixybV+W0VFhSIjI1VeXq6IiIhrPo+/WL+vWA8t267EjmHaOOMHZpcDAPBTrfH53eQ7U5GRkYqMjJRhGAoPD3f+HBkZqfj4eE2ePFl/+tOfmvzGtbW1KigoUFZW1qVirFZlZWUpLy+v0dfk5eW5tJek7OxsZ/ujR4+qqKjIpU1kZKTS09OdbXbs2KGTJ0/KarVqwIAB6ty5s+68806Xu1uNqampUUVFhcsDTbfhAEsiAAB8U5MnoL/55puSGlY6f/LJJ90e0vu2s2fPymazKS4uzuV4XFyc9u3b1+hrioqKGm1fVFTkfN5x7Eptjhw5Ikn61a9+pZdeeklJSUlatGiR/uVf/kUHDhxQx44dG33vBQsW6JlnnnHzKuHg2EJmOEN8AAAf4/acqfnz5zc7SJnJbrdLkp5++mndd999Sk1N1ZtvvimLxaJVq1Zd8XWzZs1SeXm583HixIm2KtnrfVV+UYdOn5fF0vBNPgAAfMk17efxf//3f/rLX/6iwsJC1dbWujy3Y8eOJp0jNjZWAQEBKi4udjleXFys+Pj4Rl8THx9/1faOP4uLi9W5c2eXNv3795ck5/Ebb7zR+XxISIh69OihwsLCK9YbEhLiMk8MTedYEuHmrlGKahf8Ha0BAPAubt+ZWrx4sSZMmKC4uDjt3LlTgwcPVkxMjI4cOaI777yzyecJDg5WamqqcnNzncfsdrtyc3OVkZHR6GsyMjJc2kvSunXrnO2Tk5MVHx/v0qaiokL5+fnONqmpqQoJCdH+/fudberq6nTs2DF17969yfWj6TZ+HaaG92KIDwDggww3fe973zOWL19uGIZhdOjQwTh8+LBhGIYxd+5cY8qUKW6da8WKFUZISIixbNkyY+/evcbkyZONqKgoo6ioyDAMw3jggQeMmTNnOttv3rzZCAwMNF588UXjiy++MObPn28EBQUZn332mbPNr3/9ayMqKsp4++23jU8//dS4++67jeTkZOPixYvONlOnTjW6dOli/OMf/zD27dtnTJw40ejUqZNRWlra5NrLy8sNSUZ5eblb1+xvbDa7MfDZD4zuv1xj5B0+a3Y5AAA/1xqf324P8xUWFmro0KGSpLCwMFVWVkqSHnjgAQ0ZMsS5zEFTjBo1SmfOnNG8efNUVFSk/v37a+3atc4J5IWFhbJaL908Gzp0qJYvX645c+Zo9uzZSklJ0erVq9WnTx9nmxkzZqiqqkqTJ09WWVmZMjMztXbtWoWGhjrb/OY3v1FgYKAeeOABXbx4Uenp6Vq/fr2io6Pd7Q58hy+KKlRSVat2wQEa2I3+BQD4niavM+XQo0cP/fWvf9WAAQOUlpamSZMm6Wc/+5k++OADjR49utHV0X0R60w1zesfH9aC9/fpB7076b8fHGR2OQAAP2fqOlMOP/jBD/TOO+9IkiZMmKAnnnhCt912m0aNGqV77rmnRYqC73AsiZDJfCkAgI9ye5jvjTfecC4vMGXKFMXExGjLli2666679LOf/azFC4T3qq6zKf9ow51K1pcCAPgqt8JUfX29/vM//1MPPfSQunbtKkkaPXq0Ro8e3SrFwbt9cqxUtfV2xUWEqFenDmaXAwBAq3BrmC8wMFALFy5UfX19a9UDH+JYXyqz13WNbo4NAIAvcHvO1K233qqPP/64NWqBj3GsL/X96xniAwD4LrfnTN15552aOXOmPvvsM6Wmpl62tcxdd93VYsXBe52prNHerxo2gx7G5HMAgA9zO0z94he/kCS99NJLlz1nsVhks9maXxW83pbDDXelbugcodgObMMDAPBdbocpxzf5gKtxbiHDt/gAAD7O7TlTwHcxDMM5+ZwwBQDwdYQptLjDZ86rqKJawYFWDUrqaHY5AAC0KsIUWtyGAw13pQYndVRoUIDJ1QAA0LoIU2hxzi1kGOIDAPgBwhRaVG29XVuPlEhiPz4AgH9w+9t8FRUVjR63WCwKCQlRcHBws4uC99pZeE4Xam2KaR+sGzu3zG7cAAB4MrfDVFRU1FW3BunatasefPBBzZ8/X1YrN778jWNJhGG9YmW1soUMAMD3uR2mli1bpqeffloPPvigBg8eLEnatm2b3nrrLc2ZM0dnzpzRiy++qJCQEM2ePbvFC4Zn28h8KQCAn3E7TL311ltatGiRfvrTnzqP/fjHP1bfvn31+uuvKzc3V926ddPzzz9PmPIz5Rfq9NmXZZJYXwoA4D/cHofbsmWLBgwYcNnxAQMGKC8vT5KUmZmpwsLC5lcHr7Ll8FnZDalXpw7qHBlmdjkAALQJt8NUYmKi/vCHP1x2/A9/+IMSExMlSSUlJYqOjm5+dfAqziE+vsUHAPAjbg/zvfjii7r//vv1/vvva9CgQZKk7du3a9++ffq///s/SdInn3yiUaNGtWyl8HgbD56RxBAfAMC/uB2m7rrrLu3bt0+vv/66Dhw4IEm68847tXr1aiUlJUmSfv7zn7dokfB8x0uqdKL0ogKtFqX3iDG7HAAA2ozbYUqSkpOT9etf/7qla4EXcyyJMLBbtDqEXNOvFQAAXumaPvXKysq0bds2nT59Wna73eW5cePGtUhh8C6bvg5TDPEBAPyN22Hq3Xff1dixY3X+/HlFRES4LOBpsVgIU36o3mbX5sOsLwUA8E9uf5tv+vTpeuihh3T+/HmVlZXp3LlzzkdpaWlr1AgP9+nJclVW1ysiNFA3d40yuxwAANqU22Hq5MmTeuyxx9SuXbvWqAdeyDHEN7RnrALYQgYA4GfcDlPZ2dnavn17a9QCL+WcL3U9Q3wAAP/j9pypkSNH6qmnntLevXvVt29fBQUFuTx/1113tVhx8Hzna+q1o/CcJGl4r+tMrgYAgLbndpiaNGmSJOnZZ5+97DmLxSKbzdb8quA1th4uUb3dULeO7dQthqFfAID/cTtMfXspBPi3TYf4Fh8AwL+5PWcK+CbnFjLsxwcA8FNNujO1ePFiTZ48WaGhoVq8ePFV2z722GMtUhg836myizp8pkpWS8M3+QAA8EdNClMvv/yyxo4dq9DQUL388stXbGexWAhTfsTxLb6bu0Ypsl3Qd7QGAMA3NSlMHT16tNF/hn/beIgtZAAAYM4UrondbmizY/I586UAAH7M7W/z2Ww2LVu2TLm5uY1udLx+/foWKw6ea+9XFSqtqlX74AAN6BZtdjkAAJjG7TA1depULVu2TCNHjlSfPn1cNjqG/3AsiTCkR4yCA7nBCQDwX26HqRUrVugvf/mLfvjDH7ZGPfASjiURWF8KAODv3L6lEBwcrF69erVGLfAS1XU2fXLs6y1kCFMAAD/ndpiaPn26fvvb38owjNaoB15g29FS1dbbFR8Rqp7XdTC7HAAATOX2MN+mTZv04Ycf6v3339dNN9102UbHf/vb31qsOHimTd9YEoE5cwAAf+d2mIqKitI999zTGrXAS2w8yH58AAA4uBWm6uvrdcstt+j2229XfHx8a9UED3amskZffFUhSRrG+lIAALg3ZyowMFAPP/ywampqWqseeDjHQp03do5QbIcQk6sBAMB8bk9AHzx4sHbu3NkatcALOIb4hl/PXSkAAKRrmDP1i1/8QtOnT9eXX36p1NRUtW/f3uX5m2++ucWKg2cxDEObDjWsLzW813UmVwMAgGdwO0yNHj1akvTYY485j1ksFhmGIYvFIpvN1nLVwaMcPH1exRU1Cgm0Ki2JLWQAAJCuIUwdPXq0NeqAF3AM8Q1O7qjQoACTqwEAwDO4Haa6d+/eGnXAC2xybCHDt/gAAHByO0w57N27V4WFhaqtrXU5ftdddzW7KHie2nq78o+WSpKGpzBfCgAAB7fD1JEjR3TPPffos88+c86VkuRcCZs5U75pR+E5Xai1KbZDsHrHh5tdDgAAHsPtpRGmTp2q5ORknT59Wu3atdPnn3+uDRs2KC0tTR999FErlAhPsPHrIb5hvWJltbKFDAAADm7fmcrLy9P69esVGxsrq9Uqq9WqzMxMLViwQI899hhrUPmoTY4tZJgvBQCAC7fvTNlsNoWHNwzzxMbG6tSpU5IaJqbv37+/ZauDRyi7UKtPT5ZLYr4UAADf5vadqT59+mj37t1KTk5Wenq6Fi5cqODgYL3xxhvq0aNHa9QIk205XCLDkFI6dVB8ZKjZ5QAA4FHcDlNz5sxRVVWVJOnZZ5/Vj370Iw0fPlwxMTFauXJlixcI8znmS2WmMMQHAMC3uR2msrOznf/cq1cv7du3T6WlpYqOjnZ+ow++wzCMS/vxEaYAALiM23OmHA4dOqR//OMfunjxojp27NisIpYsWaKkpCSFhoYqPT1d27Ztu2r7VatWqXfv3goNDVXfvn313nvvuTxvGIbmzZunzp07KywsTFlZWTp48GCj56qpqVH//v1lsVi0a9euZl2HLzpeckFfnruooACL0pNjzC4HAACP43aYKikp0a233qrrr79eP/zhD/XVV19JkiZOnKjp06e7XcDKlSs1bdo0zZ8/Xzt27FC/fv2UnZ2t06dPN9p+y5YtGjNmjCZOnKidO3cqJydHOTk52rNnj7PNwoULtXjxYi1dulT5+flq3769srOzVV1dfdn5ZsyYoYSEBLfr9hcbDzXclRrYLVrtQ655jVcAAHyW22HqiSeeUFBQkAoLC9WuXTvn8VGjRmnt2rVuF/DSSy9p0qRJmjBhgm688UYtXbpU7dq103//93832v63v/2t7rjjDj311FO64YYb9B//8R8aOHCgXn31VUkNd6VeeeUVzZkzR3fffbduvvlm/fGPf9SpU6e0evVql3O9//77+uCDD/Tiiy+6Xbe/cGwhwxAfAACNcztMffDBB3rhhRfUtWtXl+MpKSk6fvy4W+eqra1VQUGBsrKyLhVktSorK0t5eXmNviYvL8+lvdQwj8vR/ujRoyoqKnJpExkZqfT0dJdzFhcXa9KkSfqf//kfl1B4JTU1NaqoqHB5+Lp6m11bDpVIkjJZEgEAgEa5HaaqqqoaDR+lpaUKCQlx61xnz56VzWZTXFycy/G4uDgVFRU1+pqioqKrtnf8ebU2hmHowQcf1MMPP6y0tLQm1bpgwQJFRkY6H4mJiU16nTfb/WW5KmvqFRkWpL5dIs0uBwAAj+R2mBo+fLj++Mc/On+2WCyy2+1auHChbrnllhYtrrX87ne/U2VlpWbNmtXk18yaNUvl5eXOx4kTJ1qxQs/gWPV8WK8YBbCFDAAAjXJ7RvHChQt16623avv27aqtrdWMGTP0+eefq7S0VJs3b3brXLGxsQoICFBxcbHL8eLiYsXHxzf6mvj4+Ku2d/xZXFyszp07u7Tp37+/JGn9+vXKy8u77E5aWlqaxo4dq7feeuuy9w0JCXH7zpu323To6/WlejHEBwDAlbh9Z6pPnz46cOCAMjMzdffdd6uqqkr33nuvdu7cqZ49e7p1ruDgYKWmpio3N9d5zG63Kzc3VxkZGY2+JiMjw6W9JK1bt87ZPjk5WfHx8S5tKioqlJ+f72yzePFi7d69W7t27dKuXbucSyusXLlSzz//vFvX4Ksqq+u0o7BMEpPPAQC4mmv6rntkZKSefvppl2NffvmlJk+erDfeeMOtc02bNk3jx49XWlqaBg8erFdeeUVVVVWaMGGCJGncuHHq0qWLFixYIEmaOnWqRowYoUWLFmnkyJFasWKFtm/f7nxfi8Wixx9/XM8995xSUlKUnJysuXPnKiEhQTk5OZKkbt26udTQoUMHSVLPnj0vm1jvr7YeKZXNbqh7TDsldvzuCfoAAPirFls4qKSkRH/4wx/cDlOjRo3SmTNnNG/ePBUVFal///5au3atcwJ5YWGhrNZLN9CGDh2q5cuXa86cOZo9e7ZSUlK0evVq9enTx9lmxowZqqqq0uTJk1VWVqbMzEytXbtWoaHsK9dUjiURMntxVwoAgKuxGIZhtMSJdu/erYEDB8pms7XE6TxeRUWFIiMjVV5eroiICLPLaXE/WPSRjpyp0tJ/S9UdfRqfvwYAgLdpjc/va95OBr7rZNlFHTlTJatFyujJFjIAAFwNYQqXcQzx9UuMUmRYkMnVAADg2Zo8Z+ree++96vNlZWXNrQUeYuPX60sNZ74UAADfqclhKjLy6itgR0ZGaty4cc0uCOay2w1tOdywhczw61lfCgCA79LkMPXmm2+2Zh3wEHu/qlBpVa06hASqf2KU2eUAAODxmDMFFxu+ni81pEdHBQXw6wEAwHfh0xIuHPvxsb4UAABNQ5iC08Vam7YfOydJykxhvhQAAE1BmILTtmOlqrXZlRAZqp7XtTe7HAAAvAJhCk7OLWRSYmWxWEyuBgAA70CYgpNjfSmG+AAAaDrCFCRJpyurta+oUpI0jC1kAABoMsIUJEmbDzXclerTJUIxHUJMrgYAAO9BmIKkbwzx9WKIDwAAdxCmIMMwnOtLDU9hfSkAANxBmIIOFJ/X6coahQRaldo92uxyAADwKoQpaOPXSyIMTu6o0KAAk6sBAMC7EKagTV9PPv8+SyIAAOA2wpSfq6m3Kf9IqaSGxToBAIB7CFN+ruD4OV2ssym2Q4h6x4ebXQ4AAF6HMOXnNjmXRIhhCxkAAK4BYcrPOeZLDWe+FAAA14Qw5cfOVdXqs5PlkpgvBQDAtSJM+bHNh8/KMKTr4zooLiLU7HIAAPBKhCk/toktZAAAaDbClJ8yDMO5Hx9byAAAcO0IU37qWMkFnSy7qKAAi9J7dDS7HAAAvBZhyk9t+noLmdTu0WoXHGhyNQAAeC/ClJ/acJAlEQAAaAmEKT9Ub7Nr6+ESSVJmL+ZLAQDQHIQpP7T7yzJV1tQrql2Q+nSJNLscAAC8GmHKDzm+xTesZ6wCrGwhAwBAcxCm/JAjTLHqOQAAzUeY8jMV1XXadaJMEvOlAABoCYQpP7P1cIlsdkNJMe2U2LGd2eUAAOD1CFN+ZtMhlkQAAKAlEab8zCbmSwEA0KIIU37ky3MXdORslQKsFmX0jDG7HAAAfAJhyo847kr16xqpiNAgk6sBAMA3EKb8yEbmSwEA0OIIU37CZje02RmmmC8FAEBLIUz5ic9PlavsQp06hASqX2KU2eUAAOAzCFN+wrHq+ZAeMQoK4F87AAAthU9VP+GYfM4QHwAALYsw5Qcu1tpUcPycJMIUAAAtjTDlB/KPlqjWZleXqDAlx7Y3uxwAAHwKYcoPOOZLZfaKlcViMbkaAAB8C2HKD7CFDAAArYcw5eNOV1Rrf3GlLBZpWC/CFAAALY0w5eM2fb1QZ5+ESHVsH2xyNQAA+B7ClI/byBAfAACtijDlwwzDcN6ZGs4QHwAArYIw5cP2F1fqTGWNQoOsSk2KNrscAAB8EmHKhzm+xZeeHKOQwACTqwEAwDcRpnzYRraQAQCg1RGmfFR1nU35R0skMfkcAIDWRJjyUTuOn1N1nV3XhYfoe3HhZpcDAIDP8ogwtWTJEiUlJSk0NFTp6enatm3bVduvWrVKvXv3VmhoqPr27av33nvP5XnDMDRv3jx17txZYWFhysrK0sGDB53PHzt2TBMnTlRycrLCwsLUs2dPzZ8/X7W1ta1yfWbY+I1v8bGFDAAArcf0MLVy5UpNmzZN8+fP144dO9SvXz9lZ2fr9OnTjbbfsmWLxowZo4kTJ2rnzp3KyclRTk6O9uzZ42yzcOFCLV68WEuXLlV+fr7at2+v7OxsVVdXS5L27dsnu92u119/XZ9//rlefvllLV26VLNnz26Ta24LbCEDAEDbsBiGYZhZQHp6ugYNGqRXX31VkmS325WYmKhHH31UM2fOvKz9qFGjVFVVpTVr1jiPDRkyRP3799fSpUtlGIYSEhI0ffp0Pfnkk5Kk8vJyxcXFadmyZRo9enSjdfzmN7/Ra6+9piNHjjT6fE1NjWpqapw/V1RUKDExUeXl5YqIiLjm628NpVW1Sn1unQxD2jb7VnWKCDW7JAAAPEJFRYUiIyNb9PPb1DtTtbW1KigoUFZWlvOY1WpVVlaW8vLyGn1NXl6eS3tJys7OdrY/evSoioqKXNpERkYqPT39iueUGgJXx44dr/j8ggULFBkZ6XwkJiY26RrNsPnQWRmG9L24cIIUAACtzNQwdfbsWdlsNsXFxbkcj4uLU1FRUaOvKSoqump7x5/unPPQoUP63e9+p5/97GdXrHXWrFkqLy93Pk6cOHH1izMRQ3wAALSdQLMLMNvJkyd1xx136P7779ekSZOu2C4kJEQhISFtWNm1cdlChjAFAECrM/XOVGxsrAICAlRcXOxyvLi4WPHx8Y2+Jj4+/qrtHX825ZynTp3SLbfcoqFDh+qNN95o1rV4iqNnq3Sy7KKCA6xKT44xuxwAAHyeqWEqODhYqampys3NdR6z2+3Kzc1VRkZGo6/JyMhwaS9J69atc7ZPTk5WfHy8S5uKigrl5+e7nPPkyZP6l3/5F6WmpurNN9+U1Wr6FxtbhGPV89Tu0QoLZgsZAABam+nDfNOmTdP48eOVlpamwYMH65VXXlFVVZUmTJggSRo3bpy6dOmiBQsWSJKmTp2qESNGaNGiRRo5cqRWrFih7du3O+8sWSwWPf7443ruueeUkpKi5ORkzZ07VwkJCcrJyZF0KUh1795dL774os6cOeOs50p3xLzFRuZLAQDQpkwPU6NGjdKZM2c0b948FRUVqX///lq7dq1zAnlhYaHLXaOhQ4dq+fLlmjNnjmbPnq2UlBStXr1affr0cbaZMWOGqqqqNHnyZJWVlSkzM1Nr165VaGjDN9vWrVunQ4cO6dChQ+ratatLPSavFNEsdTa7th5p2ELm+ynXmVwNAAD+wfR1prxVa6xT0Vzbj5XqJ0vzFN0uSAVzbpPVysrnAAB8k8+tM4WW5RjiG9orliAFAEAbIUz5kI0HG+Z+De/FfCkAANoKYcpHVFTXafeX5ZKYfA4AQFsiTPmIvMMlstkN9Yhtr67R7cwuBwAAv0GY8hFsIQMAgDkIUz7CMV8qk/lSAAC0KcKUDzhRekHHSi4owGrRkJ5sIQMAQFsiTPkAx8bGAxKjFBEaZHI1AAD4F8KUD2C+FAAA5iFMeTmb3dDmww1hajhhCgCANkeY8nJ7Tpar7EKdwkMC1a9rlNnlAADgdwhTXs4xX2pIzxgFBvCvEwCAtsanr5dzLInwfYb4AAAwBWHKi12orVfB8XOSpMyU60yuBgAA/0SY8mL5R0pVZzPUJSpMSTFsIQMAgBkIU15s48FL3+KzWCwmVwMAgH8iTHmxTYca5ksNZ4gPAADTEKa8VHFFtQ4Un5fFIg1lCxkAAExDmPJSjlXP+3aJVHT7YJOrAQDAfxGmvJRjSYTMXiyJAACAmQhTXsgwDG06VCKJ/fgAADAbYcoL7Suq1NnzNQoLClBq92izywEAwK8RpryQY75Ueo+OCgkMMLkaAAD8G2HKC21gvhQAAB6DMOVlquts2na0VBLrSwEA4AkIU16m4Pg51dTb1Sk8RNfHdTC7HAAA/B5hyss4tpDJZAsZAAA8AmHKy1zaQob5UgAAeALClBcpOV+jPScrJEnDmHwOAIBHIEx5kc2HGxbq7B0frk7hoSZXAwAAJMKUV9l0kCE+AAA8DWHKSxiG4VysM5MlEQAA8BiEKS9x+EyVTpVXKzjAqsFJHc0uBwAAfI0w5SUcQ3xpSdEKC2YLGQAAPAVhyktsOtQwxMeq5wAAeBbClBeos9m19YhjCxkmnwMA4EkIU15g14kyna+pV8f2wbqxc4TZ5QAAgG8gTHmBjQca5ksN7Rkjq5UtZAAA8CSEKS+w0TlfiiE+AAA8DWHKw5VfrNPuE2WSWF8KAABPRJjycHmHS2Q3pB7XtVeXqDCzywEAAN9CmPJwGx1byLCxMQAAHokw5eEc60sxxAcAgGciTHmwE6UXdLzkggKtFg3pwRYyAAB4IsKUB9v49cbGA7pFKTw0yORqAABAYwhTHmzToYb5Upm9GOIDAMBTEaY8lM1uaPOhEklSJutLAQDgsQhTHuqzk+Uqv1in8NBA9esaaXY5AADgCghTHmrTwUtbyAQG8K8JAABPxae0h3JMPmdJBAAAPBthygNV1dRrR+E5SSzWCQCApyNMeaD8oyWqsxnqGh2m7jHtzC4HAABcBWHKAzmG+IanXCeLxWJyNQAA4GoIUx5okzNMMcQHAICnI0x5mKLyah08fV4WS8M3+QAAgGcjTHmYjV8viXBzl0hFtQs2uRoAAPBdCFMeZtMhx5IIDPEBAOANPCJMLVmyRElJSQoNDVV6erq2bdt21farVq1S7969FRoaqr59++q9995zed4wDM2bN0+dO3dWWFiYsrKydPDgQZc2paWlGjt2rCIiIhQVFaWJEyfq/PnzLX5t7qqqsclqaZh8DgAAPJ/pYWrlypWaNm2a5s+frx07dqhfv37Kzs7W6dOnG22/ZcsWjRkzRhMnTtTOnTuVk5OjnJwc7dmzx9lm4cKFWrx4sZYuXar8/Hy1b99e2dnZqq6udrYZO3asPv/8c61bt05r1qzRhg0bNHny5Fa/3u/y/41P0855tyu1e7TZpQAAgCawGIZhmFlAenq6Bg0apFdffVWSZLfblZiYqEcffVQzZ868rP2oUaNUVVWlNWvWOI8NGTJE/fv319KlS2UYhhISEjR9+nQ9+eSTkqTy8nLFxcVp2bJlGj16tL744gvdeOON+uSTT5SWliZJWrt2rX74wx/qyy+/VEJCwmXvW1NTo5qaGufPFRUVSkxMVHl5uSIiIlq0TwAAQOuoqKhQZGRki35+m3pnqra2VgUFBcrKynIes1qtysrKUl5eXqOvycvLc2kvSdnZ2c72R48eVVFRkUubyMhIpaenO9vk5eUpKirKGaQkKSsrS1arVfn5+Y2+74IFCxQZGel8JCYmXttFAwAAn2JqmDp79qxsNpvi4uJcjsfFxamoqKjR1xQVFV21vePP72rTqVMnl+cDAwPVsWPHK77vrFmzVF5e7nycOHGiiVcJAAB8WaDZBXiLkJAQhYSEmF0GAADwMKbemYqNjVVAQICKi4tdjhcXFys+Pr7R18THx1+1vePP72rz7Qnu9fX1Ki0tveL7AgAANMbUMBUcHKzU1FTl5uY6j9ntduXm5iojI6PR12RkZLi0l6R169Y52ycnJys+Pt6lTUVFhfLz851tMjIyVFZWpoKCAmeb9evXy263Kz09vcWuDwAA+D7Th/mmTZum8ePHKy0tTYMHD9Yrr7yiqqoqTZgwQZI0btw4denSRQsWLJAkTZ06VSNGjNCiRYs0cuRIrVixQtu3b9cbb7whSbJYLHr88cf13HPPKSUlRcnJyZo7d64SEhKUk5MjSbrhhht0xx13aNKkSVq6dKnq6ur0yCOPaPTo0Y1+kw8AAOBKTA9To0aN0pkzZzRv3jwVFRWpf//+Wrt2rXMCeWFhoazWSzfQhg4dquXLl2vOnDmaPXu2UlJStHr1avXp08fZZsaMGaqqqtLkyZNVVlamzMxMrV27VqGhoc42f/7zn/XII4/o1ltvldVq1X333afFixe33YUDAACfYPo6U96qNdapAAAArcvn1pkCAADwdoQpAACAZiBMAQAANANhCgAAoBkIUwAAAM1g+tII3srxJciKigqTKwEAAE3l+NxuycUMCFPXqLKyUpKUmJhociUAAMBdlZWVioyMbJFzsc7UNbLb7Tp16pTCw8NlsVha7LwVFRVKTEzUiRMnWL9K9Mc30ReX0Beu6I9L6ItL6ItLvtkX4eHhqqysVEJCgsui4M3BnalrZLVa1bVr11Y7f0REhN//8n8T/XEJfXEJfeGK/riEvriEvrjE0RctdUfKgQnoAAAAzUCYAgAAaAbClIcJCQnR/PnzFRISYnYpHoH+uIS+uIS+cEV/XEJfXEJfXNLafcEEdAAAgGbgzhQAAEAzEKYAAACagTAFAADQDIQpAACAZiBMeZglS5YoKSlJoaGhSk9P17Zt28wuqdUtWLBAgwYNUnh4uDp16qScnBzt37/fpU11dbWmTJmimJgYdejQQffdd5+Ki4tNqrjt/PrXv5bFYtHjjz/uPOZPfXHy5En927/9m2JiYhQWFqa+fftq+/btzucNw9C8efPUuXNnhYWFKSsrSwcPHjSx4tZjs9k0d+5cJScnKywsTD179tR//Md/uOwv5qv9sWHDBv34xz9WQkKCLBaLVq9e7fJ8U667tLRUY8eOVUREhKKiojRx4kSdP3++Da+iZVytL+rq6vTLX/5Sffv2Vfv27ZWQkKBx48bp1KlTLufwlb6Qvvt345sefvhhWSwWvfLKKy7HW6I/CFMeZOXKlZo2bZrmz5+vHTt2qF+/fsrOztbp06fNLq1Vffzxx5oyZYq2bt2qdevWqa6uTrfffruqqqqcbZ544gm9++67WrVqlT7++GOdOnVK9957r4lVt75PPvlEr7/+um6++WaX4/7SF+fOndOwYcMUFBSk999/X3v37tWiRYsUHR3tbLNw4UItXrxYS5cuVX5+vtq3b6/s7GxVV1ebWHnreOGFF/Taa6/p1Vdf1RdffKEXXnhBCxcu1O9+9ztnG1/tj6qqKvXr109Llixp9PmmXPfYsWP1+eefa926dVqzZo02bNigyZMnt9UltJir9cWFCxe0Y8cOzZ07Vzt27NDf/vY37d+/X3fddZdLO1/pC+m7fzcc/v73v2vr1q1KSEi47LkW6Q8DHmPw4MHGlClTnD/bbDYjISHBWLBggYlVtb3Tp08bkoyPP/7YMAzDKCsrM4KCgoxVq1Y523zxxReGJCMvL8+sMltVZWWlkZKSYqxbt84YMWKEMXXqVMMw/KsvfvnLXxqZmZlXfN5utxvx8fHGb37zG+exsrIyIyQkxPjf//3ftiixTY0cOdJ46KGHXI7de++9xtixYw3D8J/+kGT8/e9/d/7clOveu3evIcn45JNPnG3ef/99w2KxGCdPnmyz2lvat/uiMdu2bTMkGcePHzcMw3f7wjCu3B9ffvml0aVLF2PPnj1G9+7djZdfftn5XEv1B3emPERtba0KCgqUlZXlPGa1WpWVlaW8vDwTK2t75eXlkqSOHTtKkgoKClRXV+fSN71791a3bt18tm+mTJmikSNHulyz5F998c477ygtLU3333+/OnXqpAEDBui//uu/nM8fPXpURUVFLn0RGRmp9PR0n+sLSRo6dKhyc3N14MABSdLu3bu1adMm3XnnnZL8rz8cmnLdeXl5ioqKUlpamrNNVlaWrFar8vPz27zmtlReXi6LxaKoqChJ/tcXdrtdDzzwgJ566inddNNNlz3fUv3BRsce4uzZs7LZbIqLi3M5HhcXp3379plUVduz2+16/PHHNWzYMPXp00eSVFRUpODgYOdfBg5xcXEqKioyocrWtWLFCu3YsUOffPLJZc/5U18cOXJEr732mqZNm6bZs2frk08+0WOPPabg4GCNHz/eeb2N/Tfja30hSTNnzlRFRYV69+6tgIAA2Ww2Pf/88xo7dqwk+V1/ODTluouKitSpUyeX5wMDA9WxY0ef7pvq6mr98pe/1JgxY5wbHftbX7zwwgsKDAzUY4891ujzLdUfhCl4lClTpmjPnj3atGmT2aWY4sSJE5o6darWrVun0NBQs8sxld1uV1pamv7zP/9TkjRgwADt2bNHS5cu1fjx402uru395S9/0Z///GctX75cN910k3bt2qXHH39cCQkJftkfuLq6ujr99Kc/lWEYeu2118wuxxQFBQX67W9/qx07dshisbTqezHM5yFiY2MVEBBw2beyiouLFR8fb1JVbeuRRx7RmjVr9OGHH6pr167O4/Hx8aqtrVVZWZlLe1/sm4KCAp0+fVoDBw5UYGCgAgMD9fHHH2vx4sUKDAxUXFyc3/RF586ddeONN7ocu+GGG1RYWChJzuv1l/9mnnrqKc2cOVOjR49W37599cADD+iJJ57QggULJPlffzg05brj4+Mv+yJPfX29SktLfbJvHEHq+PHjWrdunfOulORffbFx40adPn1a3bp1c/59evz4cU2fPl1JSUmSWq4/CFMeIjg4WKmpqcrNzXUes9vtys3NVUZGhomVtT7DMPTII4/o73//u9avX6/k5GSX51NTUxUUFOTSN/v371dhYaHP9c2tt96qzz77TLt27XI+0tLSNHbsWOc/+0tfDBs27LIlMg4cOKDu3btLkpKTkxUfH+/SFxUVFcrPz/e5vpAavqlltbr+lR0QECC73S7J//rDoSnXnZGRobKyMhUUFDjbrF+/Xna7Xenp6W1ec2tyBKmDBw/qn//8p2JiYlye96e+eOCBB/Tpp5+6/H2akJCgp556Sv/4xz8ktWB/XPu8ebS0FStWGCEhIcayZcuMvXv3GpMnTzaioqKMoqIis0trVT//+c+NyMhI46OPPjK++uor5+PChQvONg8//LDRrVs3Y/369cb27duNjIwMIyMjw8Sq2843v81nGP7TF9u2bTMCAwON559/3jh48KDx5z//2WjXrp3xpz/9ydnm17/+tREVFWW8/fbbxqeffmrcfffdRnJysnHx4kUTK28d48ePN7p06WKsWbPGOHr0qPG3v/3NiI2NNWbMmOFs46v9UVlZaezcudPYuXOnIcl46aWXjJ07dzq/odaU677jjjuMAQMGGPn5+camTZuMlJQUY8yYMWZd0jW7Wl/U1tYad911l9G1a1dj165dLn+f1tTUOM/hK31hGN/9u/Ft3/42n2G0TH8QpjzM7373O6Nbt25GcHCwMXjwYGPr1q1ml9TqJDX6ePPNN51tLl68aPziF78woqOjjXbt2hn33HOP8dVXX5lXdBv6dpjyp7549913jT59+hghISFG7969jTfeeMPlebvdbsydO9eIi4szQkJCjFtvvdXYv3+/SdW2roqKCmPq1KlGt27djNDQUKNHjx7G008/7fIh6av98eGHHzb6d8T48eMNw2jadZeUlBhjxowxOnToYERERBgTJkwwKisrTbia5rlaXxw9evSKf59++OGHznP4Sl8Yxnf/bnxbY2GqJfrDYhjfWD4XAAAAbmHOFAAAQDMQpgAAAJqBMAUAANAMhCkAAIBmIEwBAAA0A2EKAACgGQhTAAAAzUCYAgAAaAbCFAAAQDMQpgD4tDNnzujnP/+5unXrppCQEMXHxys7O1ubN2+WJFksFq1evdrcIgF4tUCzCwCA1nTfffeptrZWb731lnr06KHi4mLl5uaqpKTE7NIA+Aj25gPgs8rKyhQdHa2PPvpII0aMuOz5pKQkHT9+3Plz9+7ddezYMUnS22+/rWeeeUZ79+5VQkKCxo8fr6efflqBgQ3/D2qxWPT73/9e77zzjj766CN17txZCxcu1E9+8pM2uTYAnoNhPgA+q0OHDurQoYNWr16tmpqay57/5JNPJElvvvmmvvrqK+fPGzdu1Lhx4zR16lTt3btXr7/+upYtW6bnn3/e5fVz587Vfffdp927d2vs2LEaPXq0vvjii9a/MAAehTtTAHzaX//6V02aNEkXL17UwIEDNWLECI0ePVo333yzpIY7TH//+9+Vk5PjfE1WVpZuvfVWzZo1y3nsT3/6k2bMmKFTp045X/fwww/rtddec7YZMmSIBg4cqN///vdtc3EAPAJ3pgD4tPvuu0+nTp3SO++8ozvuuEMfffSRBg4cqGXLll3xNbt379azzz7rvLPVoUMHTZo0SV999ZUuXLjgbJeRkeHyuoyMDO5MAX6ICegAfF5oaKhuu+023XbbbZo7d67+/d//XfPnz9eDDz7YaPvz58/rmWee0b333tvouQDgm7gzBcDv3HjjjaqqqpIkBQUFyWazuTw/cOBA7d+/X7169brsYbVe+mtz69atLq/bunWrbrjhhta/AAAehTtTAHxWSUmJ7r//fj300EO6+eabFR4eru3bt2vhwoW6++67JTV8oy83N1fDhg1TSEiIoqOjNW/ePP3oRz9St27d9JOf/ERWq1W7d+/Wnj179NxzzznPv2rVKqWlpSkzM1N//vOftW3bNv3hD38w63IBmIQJ6AB8Vk1NjX71q1/pgw8+0OHDh1VXV6fExETdf//9mj17tsLCwvTuu+9q2rRpOnbsmLp06eJcGuEf//iHnn32We3cuVNBQUHq3bu3/v3f/12TJk2S1DABfcmSJVq9erU2bNigzp0764UXXtBPf/pTE68YgBkIUwBwDRr7FiAA/8ScKQAAgGYgTAEAADQDE9AB4BowQwKAA3emAAAAmoEwBQAA0AyEKQAAgGYgTAEAADQDYQoAAKAZCFMAAADNQJgCAABoBsIUAABAM/z/z/FhuxfZJmEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shows the warmup during the first 20 steps\n",
        "\n",
        "Next, we will modify the learning rate further so that it decreases after reaching the\n",
        "maximum learning rate, which further helps improve the model training\n",
        "\n",
        "**Cosine Decay**\n",
        "\n",
        "Cosine decay reduces the learning rate following a cosine curve, starting from a maximum learning rate and decaying smoothly to a minimum (often zero) by the end of training.\n",
        "\n",
        "Smooth convergence\n",
        "\n",
        "No abrupt drops\n",
        "\n",
        "Often leads to better generalization and performance (especially in transformers and CNNs)"
      ],
      "metadata": {
        "id": "-UbiPmcYLDr9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "min_lr = 0.1 * initial_lr\n",
        "track_lrs = []\n",
        "lr_increment = (peak_lr - initial_lr) / warmup_steps\n",
        "global_step = -1\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        " for input_batch, target_batch in train_loader:\n",
        "  optimizer.zero_grad()\n",
        "  global_step += 1\n",
        "\n",
        "  # Warmup\n",
        "  if global_step < warmup_steps:\n",
        "    lr = initial_lr + global_step * lr_increment\n",
        "  else: # After warmup apply cosine\n",
        "    progress = ((global_step - warmup_steps) /\n",
        "    (total_training_steps - warmup_steps))\n",
        "    lr = min_lr + (peak_lr - min_lr) * 0.5 * (\n",
        "    1 + math.cos(math.pi * progress)\n",
        "    )\n",
        "\n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group[\"lr\"] = lr\n",
        "  track_lrs.append(optimizer.param_groups[0][\"lr\"])"
      ],
      "metadata": {
        "id": "4XrmAb3dLiAw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "plt.ylabel(\"Learning rate\")\n",
        "plt.xlabel(\"Step\")\n",
        "plt.plot(range(total_training_steps), track_lrs)\n",
        "plt.show()\n",
        "\n",
        "# We see a smooth decreasing curve"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "hIp0lqw6Lyje",
        "outputId": "c149cb3e-ce84-4876-d613-1a247b94f083"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gradient Clipping**\n",
        "\n",
        "This method involves setting a threshold above which gradients are downscaled to a predetermined maximum magnitude. This process ensures that the updates\n",
        "to the models parameters during backpropagation stay within a manageable range."
      ],
      "metadata": {
        "id": "fGqh2PsTL5wc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using previous loss batches\n",
        "\n",
        "# Cross entropy loss of a single batch\n",
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        " \"\"\" Input batch: batch of input data\n",
        " target batch: labels we wish to predict\n",
        " model: NN model\n",
        " device: CPU or GPU\"\"\"\n",
        "\n",
        " # Used more commonly for GPU\n",
        " input_batch = input_batch.to(device)\n",
        " target_batch = target_batch.to(device)\n",
        "\n",
        " # Output\n",
        " logits = model(input_batch)\n",
        "\n",
        " # Loss\n",
        " loss = torch.nn.functional.cross_entropy(\n",
        " logits.flatten(0, 1), target_batch.flatten()\n",
        " )\n",
        " return loss\n",
        "\n",
        "# Loss over all batches\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        " \"\"\" data_loader: DataLoader for providing batches of input\n",
        " model: evaluated model\n",
        " device: CPU or GPU\n",
        " num_batches: batches used to compute loss, if None, all batches are used\"\"\"\n",
        "\n",
        " # Initalize loss\n",
        " total_loss = 0.\n",
        "\n",
        " # Empty data\n",
        " if len(data_loader) == 0:\n",
        "    return float(\"nan\")\n",
        "\n",
        " # Define batches used\n",
        " elif num_batches is None:\n",
        "    num_batches = len(data_loader)\n",
        " else:\n",
        "    num_batches = min(num_batches, len(data_loader))\n",
        " # Loop over data, for each batch\n",
        " for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch( # COmputes loss\n",
        "               input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item() # Adds the loss\n",
        "        else:\n",
        "            break\n",
        "\n",
        " # Returns average loss\n",
        " return total_loss / num_batches"
      ],
      "metadata": {
        "id": "GJ6lvt-XMhfI"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "loss.backward()"
      ],
      "metadata": {
        "id": "GNoQ6yDYMyNg"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To provide a good threshold we will find the largest one\n",
        "def find_highest_gradient(model):\n",
        " max_grad = None\n",
        " for param in model.parameters():\n",
        "  if param.grad is not None:\n",
        "    grad_values = param.grad.data.flatten()\n",
        "    max_grad_param = grad_values.max()\n",
        "    if max_grad is None or max_grad_param > max_grad:\n",
        "      max_grad = max_grad_param\n",
        "  return max_grad\n",
        "print(find_highest_gradient(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5wAQzdGMyLt",
        "outputId": "c69bfe50-12fe-4e9f-f578-b4de3886501d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0006, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying gradient clipping\n",
        "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "print(find_highest_gradient(model))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZIW_KtTNQRX",
        "outputId": "0c78a2e0-7c4d-4495-f879-8b5bd11d9be4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.0002, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modified training function\n"
      ],
      "metadata": {
        "id": "sFuCA7E6NXEC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prints training and validation losses to update them\n",
        "\n",
        "def text_to_token_ids(text, tokenizer):\n",
        " \"\"\"Converts texts to token ids\"\"\"\n",
        " encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
        " # Converts TokenIds into a Pytorch tensor\n",
        " encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        " return encoded_tensor\n",
        "\n",
        "\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        " \"Changes ids to text\"\n",
        " flat = token_ids.squeeze(0)\n",
        " return tokenizer.decode(flat.tolist()) # Converts back into text\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "\n",
        " model.eval() # Dropout disappears\n",
        "\n",
        " with torch.no_grad(): # Evaluation is done, no need for gradients\n",
        "    train_loss = calc_loss_loader(\n",
        "    train_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        "    val_loss = calc_loss_loader(\n",
        "    val_loader, model, device, num_batches=eval_iter\n",
        "    )\n",
        " model.train() # Train the model\n",
        " return train_loss, val_loss\n",
        "\n",
        " # Generates a text to validate its performance during training\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        " model.eval() # No training, just word generation\n",
        " context_size = model.pos_emb.weight.shape[0] # Maximum available context length\n",
        " encoded = text_to_token_ids(start_context, tokenizer).to(device) # Tokenizing text\n",
        " with torch.no_grad():\n",
        "    token_ids = generate_text_simple(\n",
        "    model=model, idx=encoded,\n",
        "    max_new_tokens=50, context_size=context_size) # Generates 50 new tkens\n",
        "\n",
        " decoded_text = token_ids_to_text(token_ids, tokenizer) # Decoded tokens\n",
        " print(decoded_text.replace(\"\\n\", \" \"))\n",
        " model.train() # Back to"
      ],
      "metadata": {
        "id": "k4UsnN8bNa9E"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAINING MODEL\n"
      ],
      "metadata": {
        "id": "iMlACvyNNq-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, optimizer, device,\n",
        " n_epochs, eval_freq, eval_iter, start_context, tokenizer,\n",
        " warmup_steps, initial_lr=3e-05, min_lr=1e-6):\n",
        "\n",
        " train_losses, val_losses, track_tokens_seen, track_lrs = [], [], [], []\n",
        " tokens_seen, global_step = 0, -1\n",
        " peak_lr = optimizer.param_groups[0][\"lr\"]\n",
        " total_training_steps = len(train_loader) * n_epochs\n",
        " lr_increment = (peak_lr - initial_lr) / warmup_steps\n",
        "\n",
        " for epoch in range(n_epochs):\n",
        "  model.train()\n",
        "  for input_batch, target_batch in train_loader:\n",
        "    optimizer.zero_grad()\n",
        "    global_step += 1\n",
        "\n",
        "    # Learning Rate\n",
        "    if global_step < warmup_steps:\n",
        "      lr = initial_lr + global_step * lr_increment\n",
        "    else:\n",
        "      progress = ((global_step - warmup_steps) /\n",
        "      (total_training_steps - warmup_steps))\n",
        "      lr = min_lr + (peak_lr - min_lr) * 0.5 * (\n",
        "      1 + math.cos(math.pi * progress))\n",
        "\n",
        "    for param_group in optimizer.param_groups:\n",
        "      param_group[\"lr\"] = lr\n",
        "    track_lrs.append(lr)\n",
        "    loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "    loss.backward()\n",
        "\n",
        "    # Gradient clipping\n",
        "    if global_step > warmup_steps:\n",
        "      torch.nn.utils.clip_grad_norm_(\n",
        "      model.parameters(), max_norm=1.0\n",
        "      )\n",
        "\n",
        "    # Same code as before\n",
        "    optimizer.step()\n",
        "    tokens_seen += input_batch.numel()\n",
        "\n",
        "    if global_step % eval_freq == 0:\n",
        "      train_loss, val_loss = evaluate_model(\n",
        "      model, train_loader, val_loader,\n",
        "      device, eval_iter\n",
        "      )\n",
        "      train_losses.append(train_loss)\n",
        "      val_losses.append(val_loss)\n",
        "      track_tokens_seen.append(tokens_seen)\n",
        "      print(f\"Ep {epoch+1} (Iter {global_step:06d}): \"\n",
        "      f\"Train loss {train_loss:.3f}, \"\n",
        "      f\"Val loss {val_loss:.3f}\"\n",
        "      )\n",
        "\n",
        "  generate_and_print_sample(\n",
        "  model, tokenizer, device, start_context\n",
        "  )\n",
        " return train_losses, val_losses, track_tokens_seen, track_lrs"
      ],
      "metadata": {
        "id": "wBJhVNY7NsnH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training model\n",
        "import tiktoken\n",
        "torch.manual_seed(123)\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "peak_lr = 5e-4\n",
        "optimizer = torch.optim.AdamW(model.parameters(), weight_decay=0.1)\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "n_epochs = 15\n",
        "train_losses, val_losses, tokens_seen, lrs = train_model(\n",
        " model, train_loader, val_loader, optimizer, device, n_epochs=n_epochs,\n",
        " eval_freq=5, eval_iter=1, start_context=\"Every effort moves you\",\n",
        " tokenizer=tokenizer, warmup_steps=warmup_steps,\n",
        " initial_lr=1e-5, min_lr=1e-5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEG3U-1COY7G",
        "outputId": "f06a2800-6f2e-4d54-9a10-fc70bd7dfea4"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Iter 000000): Train loss 10.970, Val loss 10.938\n",
            "Ep 1 (Iter 000005): Train loss 9.336, Val loss 9.460\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "Ep 2 (Iter 000010): Train loss 7.820, Val loss 8.186\n",
            "Ep 2 (Iter 000015): Train loss 6.344, Val loss 6.892\n",
            "Every effort moves you,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
            "Ep 3 (Iter 000020): Train loss 6.076, Val loss 6.595\n",
            "Ep 3 (Iter 000025): Train loss 5.681, Val loss 6.771\n",
            "Every effort moves you, the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the of the\n",
            "Ep 4 (Iter 000030): Train loss 5.803, Val loss 6.841\n",
            "Ep 4 (Iter 000035): Train loss 5.784, Val loss 6.837\n",
            "Every effort moves you.                                                 \n",
            "Ep 5 (Iter 000040): Train loss 5.353, Val loss 6.689\n",
            "Every effort moves you.  \".  \"- it.                                       \n",
            "Ep 6 (Iter 000045): Train loss 4.935, Val loss 6.611\n",
            "Ep 6 (Iter 000050): Train loss 4.291, Val loss 6.370\n",
            "Every effort moves you know the picture and in the picture                                           \n",
            "Ep 7 (Iter 000055): Train loss 3.849, Val loss 6.328\n",
            "Ep 7 (Iter 000060): Train loss 2.739, Val loss 6.170\n",
            "Every effort moves you know it was his a little to me--and the fact of the last I felt to me--I looked up, I felt to see a little of the fact that he was his pictures--the, and, and--I didn't, I\n",
            "Ep 8 (Iter 000065): Train loss 2.603, Val loss 6.154\n",
            "Ep 8 (Iter 000070): Train loss 2.346, Val loss 6.178\n",
            "Every effort moves you know the was not that I felt--I had the fact with the last I had been--and I looked up, I had been hardisburn, with a later-curtains, I had the donkey. Gisburn, I had\n",
            "Ep 9 (Iter 000075): Train loss 1.898, Val loss 6.176\n",
            "Ep 9 (Iter 000080): Train loss 1.060, Val loss 6.235\n",
            "Every effort moves you?\"  \"I must.\"   \"--as such--had not to my work, and up, I felt to see a smile behind his close grayish beard--as if he had the donkey. \"There were, I had\n",
            "Ep 10 (Iter 000085): Train loss 1.131, Val loss 6.292\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the fact with that point I could have given Miss Croft the fullest reassurance. I was just because she was _not_ interesting--if I had the donkey. \"There were days when I\n",
            "Ep 11 (Iter 000090): Train loss 0.662, Val loss 6.266\n",
            "Ep 11 (Iter 000095): Train loss 0.595, Val loss 6.355\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. \"Oh, so disarming, and went on groping and Mrs. \" back his head to look up at the honour being _mine_--because he didn't want\n",
            "Ep 12 (Iter 000100): Train loss 0.438, Val loss 6.366\n",
            "Ep 12 (Iter 000105): Train loss 0.327, Val loss 6.384\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
            "Ep 13 (Iter 000110): Train loss 0.344, Val loss 6.461\n",
            "Ep 13 (Iter 000115): Train loss 0.243, Val loss 6.465\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
            "Ep 14 (Iter 000120): Train loss 0.240, Val loss 6.475\n",
            "Ep 14 (Iter 000125): Train loss 0.213, Val loss 6.478\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n",
            "Ep 15 (Iter 000130): Train loss 0.200, Val loss 6.482\n",
            "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like pretraining, the model begins to overfit after a few epochs since it is a very small\n",
        "dataset, and we iterate over it multiple times. Nonetheless, we can see that the function is working since it minimizes the training set loss"
      ],
      "metadata": {
        "id": "RXofM4HBOf7k"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNA0iS6ZU16Ix1hIwVCi09J",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}